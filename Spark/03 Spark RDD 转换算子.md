[TOC]

## Spark RDD 转换算子

> 对 rdd：{1, 2, 3, 3} 进行转换

| 算子名     | 算子中自定义函数的介绍                 | 示例                          | 结果                  |
| ---------- | -------------------------------------- | ----------------------------- | --------------------- |
| *map*      | 接收：旧单个元素，返回：新的单个元素   | ```rdd.map(x => x+1)```       | {2，3，4，4}          |
| *flatMap*  | 接收：旧单个元素，返回：新元素的迭代器 | ```rdd.map(x => x.to(3))```   | {1, 2, 3, 2, 3, 3, 3} |
| *filter*   | 接收：旧单个元素，返回：boolean        | ```rdd.filter(x => x == 1)``` | {1}                   |
| *distinct* | 无                                     | ```rdd.distinct()```          | {1, 2, 3}             |

> 对rdd：{1，2，3}，other：{3，4，5} 进行转换

| 算子名  | 算子中自定义函数的介绍                          | 示例                   | 结果               |
| ------- | ----------------------------------------------- | ---------------------- | ------------------ |
| *union* | 接收：单个rdd或集合的rdd，返回：一个聚合后的rdd | ```rdd.union(other)``` | {1, 2, 3, 3, 4, 5} |

> 对Pair RDD的转换操作（{(1, 2), (3, 4), (3, 6)}）

| 算子名       | 目的                     | 示例                   | 结果                    |
| ------------ | ------------------------ | ---------------------- | ----------------------- |
| *groupByKey* | 对具有相同键的值进行分组 | ```rdd.groupByKey()``` | {(1, [2]), (3, [4, 6])} |

> mapPartitions 与 map 类似，只不过映射函数的参数由RDD中的每一个元素变成了RDD中每一个分区的迭代器。如果在映射的过程中需要频繁创建额外的对象，使用mapPartitions要比map更高效。